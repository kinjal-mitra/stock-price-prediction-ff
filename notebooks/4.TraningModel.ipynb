{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9d10b8",
   "metadata": {},
   "source": [
    "## 1. Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "id": "2811d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c909c",
   "metadata": {},
   "source": [
    "## 2. Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "id": "1ce06888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Setting seed for all GPUs.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Setting seed for all GPUs.\")\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afcbf0",
   "metadata": {},
   "source": [
    "## 3. Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1703,
   "id": "e3fa83a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/Kinjal Mitra/Documents/stock-price-prediction-ff/data/raw'),\n",
       " WindowsPath('C:/Users/Kinjal Mitra/Documents/stock-price-prediction-ff/data/interim'),\n",
       " WindowsPath('C:/Users/Kinjal Mitra/Documents/stock-price-prediction-ff/reports/figures'))"
      ]
     },
     "execution_count": 1703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Project Root Resolution\n",
    "# -----------------------------\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[0]\n",
    "\n",
    "DATA_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"reports\" / \"figures\"\n",
    "\n",
    "DATA_INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_RAW_DIR, DATA_INTERIM_DIR, FIGURES_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcf555",
   "metadata": {},
   "source": [
    "## 4. Load Data from data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "id": "a0a66d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA_PROCESSED_DIR /\"processed_dataset.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "id": "493a1e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Data_Value</th>\n",
       "      <th>StockPrice</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>log_return</th>\n",
       "      <th>price_change</th>\n",
       "      <th>volatility_7d</th>\n",
       "      <th>MA_7</th>\n",
       "      <th>MA_30</th>\n",
       "      <th>MA_50</th>\n",
       "      <th>...</th>\n",
       "      <th>bollinger_lower</th>\n",
       "      <th>momentum_5d</th>\n",
       "      <th>momentum_20d</th>\n",
       "      <th>price_lag_1</th>\n",
       "      <th>price_lag_2</th>\n",
       "      <th>price_lag_3</th>\n",
       "      <th>price_lag_4</th>\n",
       "      <th>price_lag_5</th>\n",
       "      <th>rolling_max_20d</th>\n",
       "      <th>rolling_min_20d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1178.00</td>\n",
       "      <td>-0.002962</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>1184.892857</td>\n",
       "      <td>1152.920000</td>\n",
       "      <td>1160.837</td>\n",
       "      <td>...</td>\n",
       "      <td>1115.877196</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>1181.50</td>\n",
       "      <td>1182.25</td>\n",
       "      <td>1186.75</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1191.75</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1119.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1181.50</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>1186.714286</td>\n",
       "      <td>1151.945000</td>\n",
       "      <td>1161.577</td>\n",
       "      <td>...</td>\n",
       "      <td>1113.758332</td>\n",
       "      <td>-0.001479</td>\n",
       "      <td>0.031202</td>\n",
       "      <td>1182.25</td>\n",
       "      <td>1186.75</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1191.75</td>\n",
       "      <td>1183.25</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1119.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>0.694</td>\n",
       "      <td>1182.25</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>-0.003799</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>1188.571429</td>\n",
       "      <td>1151.053333</td>\n",
       "      <td>1162.252</td>\n",
       "      <td>...</td>\n",
       "      <td>1111.799951</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>1186.75</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1191.75</td>\n",
       "      <td>1183.25</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1119.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>0.692</td>\n",
       "      <td>1186.75</td>\n",
       "      <td>-0.003359</td>\n",
       "      <td>-0.003365</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>1188.464286</td>\n",
       "      <td>1150.161667</td>\n",
       "      <td>1162.812</td>\n",
       "      <td>...</td>\n",
       "      <td>1103.950485</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>0.070108</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1191.75</td>\n",
       "      <td>1183.25</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1194.50</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1111.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>1189.642857</td>\n",
       "      <td>1149.161667</td>\n",
       "      <td>1163.397</td>\n",
       "      <td>...</td>\n",
       "      <td>1097.085188</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.077358</td>\n",
       "      <td>1191.75</td>\n",
       "      <td>1183.25</td>\n",
       "      <td>1190.75</td>\n",
       "      <td>1194.50</td>\n",
       "      <td>1181.50</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2.782</td>\n",
       "      <td>5959.25</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>5927.357143</td>\n",
       "      <td>6056.241667</td>\n",
       "      <td>5950.645</td>\n",
       "      <td>...</td>\n",
       "      <td>5854.670147</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>-0.024034</td>\n",
       "      <td>5944.75</td>\n",
       "      <td>5866.25</td>\n",
       "      <td>5874.50</td>\n",
       "      <td>5882.25</td>\n",
       "      <td>5989.00</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>5866.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>2.789</td>\n",
       "      <td>5944.75</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>78.50</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>5937.964286</td>\n",
       "      <td>6058.566667</td>\n",
       "      <td>5945.825</td>\n",
       "      <td>...</td>\n",
       "      <td>5861.877525</td>\n",
       "      <td>-0.005146</td>\n",
       "      <td>-0.017315</td>\n",
       "      <td>5866.25</td>\n",
       "      <td>5874.50</td>\n",
       "      <td>5882.25</td>\n",
       "      <td>5989.00</td>\n",
       "      <td>5975.50</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>5866.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>2025-01-10</td>\n",
       "      <td>2.766</td>\n",
       "      <td>5866.25</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.001405</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>5957.892857</td>\n",
       "      <td>6060.433333</td>\n",
       "      <td>5943.240</td>\n",
       "      <td>...</td>\n",
       "      <td>5872.408570</td>\n",
       "      <td>-0.027720</td>\n",
       "      <td>-0.036543</td>\n",
       "      <td>5874.50</td>\n",
       "      <td>5882.25</td>\n",
       "      <td>5989.00</td>\n",
       "      <td>5975.50</td>\n",
       "      <td>6033.50</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>5866.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>2.785</td>\n",
       "      <td>5874.50</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>-7.75</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>5994.214286</td>\n",
       "      <td>6063.891667</td>\n",
       "      <td>5942.445</td>\n",
       "      <td>...</td>\n",
       "      <td>5903.923835</td>\n",
       "      <td>-0.034474</td>\n",
       "      <td>-0.035742</td>\n",
       "      <td>5882.25</td>\n",
       "      <td>5989.00</td>\n",
       "      <td>5975.50</td>\n",
       "      <td>6033.50</td>\n",
       "      <td>6084.25</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>5874.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>2.761</td>\n",
       "      <td>5882.25</td>\n",
       "      <td>-0.017824</td>\n",
       "      <td>-0.017985</td>\n",
       "      <td>-106.75</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>6033.857143</td>\n",
       "      <td>6067.100000</td>\n",
       "      <td>5940.145</td>\n",
       "      <td>...</td>\n",
       "      <td>5939.847927</td>\n",
       "      <td>-0.038927</td>\n",
       "      <td>-0.031370</td>\n",
       "      <td>5989.00</td>\n",
       "      <td>5975.50</td>\n",
       "      <td>6033.50</td>\n",
       "      <td>6084.25</td>\n",
       "      <td>6120.50</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>5882.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3753 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Data_Value  StockPrice  daily_return  log_return  \\\n",
       "0     2010-01-04       0.700     1178.00     -0.002962   -0.002967   \n",
       "1     2010-01-05       0.699     1181.50     -0.000634   -0.000635   \n",
       "2     2010-01-06       0.694     1182.25     -0.003792   -0.003799   \n",
       "3     2010-01-07       0.692     1186.75     -0.003359   -0.003365   \n",
       "4     2010-01-08       0.691     1190.75     -0.000839   -0.000839   \n",
       "...          ...         ...         ...           ...         ...   \n",
       "3748  2025-01-08       2.782     5959.25      0.002439    0.002436   \n",
       "3749  2025-01-09       2.789     5944.75      0.013382    0.013293   \n",
       "3750  2025-01-10       2.766     5866.25     -0.001404   -0.001405   \n",
       "3751  2025-01-13       2.785     5874.50     -0.001318   -0.001318   \n",
       "3752  2025-01-14       2.761     5882.25     -0.017824   -0.017985   \n",
       "\n",
       "      price_change  volatility_7d         MA_7        MA_30     MA_50  ...  \\\n",
       "0            -3.50       0.004291  1184.892857  1152.920000  1160.837  ...   \n",
       "1            -0.75       0.004301  1186.714286  1151.945000  1161.577  ...   \n",
       "2            -4.50       0.006435  1188.571429  1151.053333  1162.252  ...   \n",
       "3            -4.00       0.007695  1188.464286  1150.161667  1162.812  ...   \n",
       "4            -1.00       0.008593  1189.642857  1149.161667  1163.397  ...   \n",
       "...            ...            ...          ...          ...       ...  ...   \n",
       "3748         14.50       0.009858  5927.357143  6056.241667  5950.645  ...   \n",
       "3749         78.50       0.009941  5937.964286  6058.566667  5945.825  ...   \n",
       "3750         -8.25       0.006703  5957.892857  6060.433333  5943.240  ...   \n",
       "3751         -7.75       0.006418  5994.214286  6063.891667  5942.445  ...   \n",
       "3752       -106.75       0.007180  6033.857143  6067.100000  5940.145  ...   \n",
       "\n",
       "      bollinger_lower  momentum_5d  momentum_20d  price_lag_1  price_lag_2  \\\n",
       "0         1115.877196    -0.011538      0.027475      1181.50      1182.25   \n",
       "1         1113.758332    -0.001479      0.031202      1182.25      1186.75   \n",
       "2         1111.799951    -0.007138      0.064131      1186.75      1190.75   \n",
       "3         1103.950485    -0.006488      0.070108      1190.75      1191.75   \n",
       "4         1097.085188     0.007829      0.077358      1191.75      1183.25   \n",
       "...               ...          ...           ...          ...          ...   \n",
       "3748      5854.670147    -0.004967     -0.024034      5944.75      5866.25   \n",
       "3749      5861.877525    -0.005146     -0.017315      5866.25      5874.50   \n",
       "3750      5872.408570    -0.027720     -0.036543      5874.50      5882.25   \n",
       "3751      5903.923835    -0.034474     -0.035742      5882.25      5989.00   \n",
       "3752      5939.847927    -0.038927     -0.031370      5989.00      5975.50   \n",
       "\n",
       "      price_lag_3  price_lag_4  price_lag_5  rolling_max_20d  rolling_min_20d  \n",
       "0         1186.75      1190.75      1191.75           1195.0          1119.75  \n",
       "1         1190.75      1191.75      1183.25           1195.0          1119.75  \n",
       "2         1191.75      1183.25      1190.75           1195.0          1119.75  \n",
       "3         1183.25      1190.75      1194.50           1195.0          1111.00  \n",
       "4         1190.75      1194.50      1181.50           1195.0          1109.00  \n",
       "...           ...          ...          ...              ...              ...  \n",
       "3748      5874.50      5882.25      5989.00           6152.0          5866.25  \n",
       "3749      5882.25      5989.00      5975.50           6152.0          5866.25  \n",
       "3750      5989.00      5975.50      6033.50           6152.0          5866.25  \n",
       "3751      5975.50      6033.50      6084.25           6152.0          5874.50  \n",
       "3752      6033.50      6084.25      6120.50           6152.0          5882.25  \n",
       "\n",
       "[3753 rows x 28 columns]"
      ]
     },
     "execution_count": 1705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "id": "4dacf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = np.load(DATA_PROCESSED_DIR / \"X_features.npy\")\n",
    "y = np.load(DATA_PROCESSED_DIR / \"y_target.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220b3ad",
   "metadata": {},
   "source": [
    "## 5. Create time-series sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d64a5",
   "metadata": {},
   "source": [
    "#### Sequence creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "id": "21736dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, lookback):\n",
    "    \"\"\"\n",
    "    Create rolling window sequences for time series forecasting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Scaled feature matrix of shape (n_samples, n_features)\n",
    "    y : np.ndarray\n",
    "        Target array of shape (n_samples,)\n",
    "    lookback : int\n",
    "        Number of past timesteps to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_seq : np.ndarray\n",
    "        Shape: (n_sequences, lookback, n_features)\n",
    "    y_seq : np.ndarray\n",
    "        Shape: (n_sequences,)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_seq, y_seq = [], []\n",
    "\n",
    "    for i in range(lookback, len(X)):\n",
    "        X_seq.append(X[i - lookback:i])\n",
    "        y_seq.append(y[i])\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104024da",
   "metadata": {},
   "source": [
    "#### Choose lookback window and generate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "id": "1b7d2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 25  # Number of days to look back for features\n",
    "X_seq, y_seq = create_sequences(X_scaled, y, LOOKBACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12789bb",
   "metadata": {},
   "source": [
    "#### Verify Shapes of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "id": "5dbff8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq shape: (3728, 25, 26)\n",
      "y_seq shape: (3728,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_seq shape:\", X_seq.shape)\n",
    "print(\"y_seq shape:\", y_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "id": "71648375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026929998321919\n",
      "0.0026929998321919\n"
     ]
    }
   ],
   "source": [
    "# This should correspond to y at time t\n",
    "print(y[LOOKBACK])\n",
    "print(y_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90d2ed",
   "metadata": {},
   "source": [
    "## 6. Train / Validation / Test split (time-aware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b157291",
   "metadata": {},
   "source": [
    "\n",
    "70% → Training\n",
    "\n",
    "15% → Validation\n",
    "\n",
    "15% → Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb485d",
   "metadata": {},
   "source": [
    "#### Split the data into training, validation, and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "e06d4b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_samples = X_seq.shape[0]\n",
    "\n",
    "train_size = int(0.7 * n_samples)\n",
    "val_size = int(0.15 * n_samples)\n",
    "\n",
    "X_train = X_seq[:train_size]\n",
    "y_train = y_seq[:train_size]\n",
    "\n",
    "X_val = X_seq[train_size:train_size + val_size]\n",
    "y_val = y_seq[train_size:train_size + val_size]\n",
    "\n",
    "X_test = X_seq[train_size + val_size:]\n",
    "y_test = y_seq[train_size + val_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7e10c",
   "metadata": {},
   "source": [
    "#### Verify shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "id": "798244b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2609, 25, 26) (2609,)\n",
      "Val  : (559, 25, 26) (559,)\n",
      "Test : (560, 25, 26) (560,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val  :\", X_val.shape, y_val.shape)\n",
    "print(\"Test :\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ca878",
   "metadata": {},
   "source": [
    "#### Save Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "74709e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS_DIR = DATA_PROCESSED_DIR/\"splits\"\n",
    "np.save(SPLITS_DIR/\"X_train.npy\", X_train)\n",
    "np.save(SPLITS_DIR/\"y_train.npy\", y_train)\n",
    "np.save(SPLITS_DIR/\"X_val.npy\", X_val)\n",
    "np.save(SPLITS_DIR/\"y_val.npy\", y_val)\n",
    "np.save(SPLITS_DIR/\"X_test.npy\", X_test)\n",
    "np.save(SPLITS_DIR/\"y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab39da",
   "metadata": {},
   "source": [
    "## 7. GRU Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "id": "f0cd4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=64,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            device=x.device\n",
    "        )\n",
    "\n",
    "        # GRU forward\n",
    "        out, _ = self.gru(x, h0)\n",
    "\n",
    "        # Take last time step\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Final regression output\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73774102",
   "metadata": {},
   "source": [
    "#### Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "id": "5bb03786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUModel(\n",
      "  (gru): GRU(26, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[2]\n",
    "\n",
    "model = GRUModel(\n",
    "    input_size=input_size,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e26837",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617db97",
   "metadata": {},
   "source": [
    "#### Convert NumPy arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1716,
   "id": "ca1c0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48113576",
   "metadata": {},
   "source": [
    "#### Create DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "id": "c42e7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192fd73c",
   "metadata": {},
   "source": [
    "#### Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "0407437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"Using device:\", device)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161cde9",
   "metadata": {},
   "source": [
    "#### Loss function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1719,
   "id": "f90fd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd60b8",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "id": "baee40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "PATIENCE = 5   # stop if val loss doesn't improve for 5 epochs\n",
    "MIN_DELTA = 1e-6  # minimum improvement threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "id": "bba4a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] | Train Loss: 0.000059 | Val Loss: 0.000049\n",
      "Epoch [10/50] | Train Loss: 0.000046 | Val Loss: 0.000040\n",
      "\n",
      "Early stopping triggered at epoch 14. Best Val Loss: 0.000041\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -----------------\n",
    "    # Training\n",
    "    # -----------------\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # -----------------\n",
    "    # Validation\n",
    "    # -----------------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    # -----------------\n",
    "    # Early stopping check\n",
    "    # -----------------\n",
    "    if val_loss < best_val_loss - MIN_DELTA:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"best_gru_model.pt\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # -----------------\n",
    "    # Logging every 5 epochs\n",
    "    # -----------------\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "            f\"Train Loss: {train_loss:.6f} | \"\n",
    "            f\"Val Loss: {val_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "    # -----------------\n",
    "    # Stop condition\n",
    "    # -----------------\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(\n",
    "            f\"\\nEarly stopping triggered at epoch {epoch+1}. \"\n",
    "            f\"Best Val Loss: {best_val_loss:.6f}\"\n",
    "        )\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596f3ff",
   "metadata": {},
   "source": [
    "#### Load best model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "id": "b4406f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (gru): GRU(26, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_gru_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadcc1a",
   "metadata": {},
   "source": [
    "## 9. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "id": "b4ab4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test tensors\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Generate predictions on test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t)\n",
    "\n",
    "# Move to CPU and convert to numpy for metric calculations    \n",
    "y_pred = y_pred.cpu().numpy()\n",
    "y_true = y_test_t.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "id": "94906869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.0109\n",
      "Root Mean Squared Error (RMSE): 0.0126\n",
      "R-squared (R2) Score: -1.1228\n",
      "Directional Accuracy: 55.00%\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# R-squared (R2) Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "\n",
    "# Directional accuracy\n",
    "direction_true = np.sign(y_true)\n",
    "direction_pred = np.sign(y_pred)\n",
    "\n",
    "directional_accuracy = (direction_true == direction_pred).mean()\n",
    "print(f\"Directional Accuracy: {directional_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6213b75",
   "metadata": {},
   "source": [
    "## 10. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fd2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] | Train Loss: 0.016224 | Val Loss: 0.036622\n",
      "\n",
      "Early stopping triggered at epoch 6. Best Val Loss: 0.036622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(26, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=64,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # Same regression head as GRU\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            device=x.device\n",
    "        )\n",
    "        c0 = torch.zeros(\n",
    "            self.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            device=x.device\n",
    "        )\n",
    "\n",
    "        # LSTM forward\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Take last time step\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Final regression output\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out.squeeze()\n",
    "\n",
    "# Model Initialization\n",
    "model = LSTMModel(\n",
    "    input_size=X_train.shape[2],\n",
    "    hidden_size=96,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Training \n",
    "EPOCHS = 50\n",
    "PATIENCE = 5   # stop if val loss doesn't improve for 5 epochs\n",
    "MIN_DELTA = 1e-6  # minimum improvement threshold\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -----------------\n",
    "    # Training\n",
    "    # -----------------\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # -----------------\n",
    "    # Validation\n",
    "    # -----------------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    # -----------------\n",
    "    # Early stopping check\n",
    "    # -----------------\n",
    "    if val_loss < best_val_loss - MIN_DELTA:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"best_lstm_model.pt\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # -----------------\n",
    "    # Logging every 5 epochs\n",
    "    # -----------------\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "            f\"Train Loss: {train_loss:.6f} | \"\n",
    "            f\"Val Loss: {val_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "    # -----------------\n",
    "    # Stop condition\n",
    "    # -----------------\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(\n",
    "            f\"\\nEarly stopping triggered at epoch {epoch+1}. \"\n",
    "            f\"Best Val Loss: {best_val_loss:.6f}\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"best_lstm_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "1ea56844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.3397\n",
      "Root Mean Squared Error (RMSE): 0.3420\n",
      "R-squared (R2) Score: -1569.1715\n",
      "Directional Accuracy: 54.46%\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# Prepare test tensors\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Generate predictions on test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t)\n",
    "\n",
    "# Move to CPU and convert to numpy for metric calculations    \n",
    "y_pred = y_pred.cpu().numpy()\n",
    "y_true = y_test_t.cpu().numpy()\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# R-squared (R2) Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "\n",
    "# Directional accuracy\n",
    "direction_true = np.sign(y_true)\n",
    "direction_pred = np.sign(y_pred)\n",
    "\n",
    "directional_accuracy = (direction_true == direction_pred).mean()\n",
    "print(f\"Directional Accuracy: {directional_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e1df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
